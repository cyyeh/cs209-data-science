{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <img style=\"float: left; padding-right: 10px; width: 45px\" src=\"https://raw.githubusercontent.com/Harvard-IACS/2018-CS109A/master/content/styles/iacs.png\"> CS-109A Introduction to Data Science\n",
    "\n",
    "\n",
    "## Lab 12: Building and Regularizing your first Neural Network \n",
    "\n",
    "**Harvard University**<br>\n",
    "**Fall 2019**<br>\n",
    "**Instructors:** Pavlos Protopapas, Kevin Rader, Chris Tanner<br>\n",
    "**Lab Instructors:** Chris Tanner and Eleni Kaxiras.  <br>\n",
    "**Authors:** Eleni Kaxiras, David Sondak, and Pavlos Protopapas. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## RUN THIS CELL TO PROPERLY HIGHLIGHT THE EXERCISES\n",
    "import requests\n",
    "from IPython.core.display import HTML\n",
    "styles = requests.get(\"https://raw.githubusercontent.com/Harvard-IACS/2018-CS109A/master/content/styles/cs109.css\").text\n",
    "HTML(styles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "%matplotlib inline\n",
    "\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "\n",
    "# TensorFlow and tf.keras\n",
    "import tensorflow as tf\n",
    "\n",
    "tf.keras.backend.clear_session()  # For easy reset of notebook state.\n",
    "\n",
    "print(tf.__version__)  # You should see a 2.0.0 here!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Picking up where we left off `tf.keras` with Tensorflow 2.0:  \n",
    "\n",
    "```              \n",
    "tf.keras.models.Sequential\n",
    "tf.keras.layers.Dense, tf.keras.layers.Activation, \n",
    "tf.keras.layers.Dropout, tf.keras.layers.Flatten, tf.keras.layers.Reshape\n",
    "tf.keras.optimizers.SGD\n",
    "tf.keras.preprocessing.image.ImageDataGenerator\n",
    "tf.keras.regularizers\n",
    "tf.keras.datasets.mnist   \n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learning Goals\n",
    "In this lab we will continue with the basics of feedforward neural networks, we will create one and explore various ways to optimize and regularize it using `tf.keras`, a deep learning library inside the broader framework called [Tensorflow](https://www.tensorflow.org). By the end of this lab, you should:\n",
    "\n",
    "- Understand how a simple neural network works and code some of its functionality using `tf.keras`.\n",
    "- Think of vectors and arrays as tensors. Learn how to do basic image manipulations.\n",
    "- Implement a simple real world example using a neural network. Find ways to improve its performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Motivation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"exercise\"><b>In class discussion : why do we care about Neural Nets?</b></div>\n",
    "\n",
    "**Buzzwords**: Linearity, Interpretability, Performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Data Preparation\n",
    "\n",
    "### Tensors\n",
    "\n",
    "We can think of tensors as multidimensional arrays of real numerical values; their job is to generalize matrices to multiple dimensions. \n",
    "\n",
    "- **scalar** = just a number = rank 0 tensor  ($a$ ∈ $F$,)\n",
    "<BR><BR>\n",
    "    \n",
    "- **vector** = 1D array = rank 1 tensor ( $x = (\\;x_1,...,x_i\\;)⊤$ ∈ $F^n$ )\n",
    "<BR><BR>\n",
    "    \n",
    "- **matrix** = 2D array = rank 2 tensor ( $\\textbf{X} = [a_{ij}] ∈ F^{m×n}$ )\n",
    "<BR><BR>\n",
    "    \n",
    "- **3D array** = rank 3 tensor ( $\\mathscr{X} =[t_{i,j,k}]∈F^{m×n×l}$ )\n",
    "<BR><BR>\n",
    "    \n",
    "- **$\\mathscr{N}$D array** = rank $\\mathscr{N}$ tensor ( $\\mathscr{T} =[t_{i1},...,t_{i\\mathscr{N}}]∈F^{n_1×...×n_\\mathscr{N}}$ ) <-- **Things start to get complicated here...**\n",
    "    \n",
    "#### Tensor indexing\n",
    "We can create subarrays by fixing some of the given tensor’s indices. We can create a vector by fixing all but one index. A 2D matrix is created when fixing all but two indices. For example, for a third order tensor the vectors are\n",
    "<br><BR>\n",
    "$\\mathscr{X}[:,j,k]$ = $\\mathscr{X}[j,k]$ (column), <br>\n",
    "$\\mathscr{X}[i,:,k]$ = $\\mathscr{X}[i,k]$ (row), and <BR>\n",
    "$\\mathscr{X}[i,j,:]$ = $\\mathscr{X}[i,j]$ (tube) <BR>\n",
    " \n",
    "#### Tensor multiplication\n",
    "We can multiply one matrix with another as long as the sizes are compatible ((n × m) × (m × p) = n × p), and also multiply an entire matrix by a constant. Numpy `numpy.dot` performs a matrix multiplication which is straightforward when we have 2D or 1D arrays. But what about > 3D arrays? The function will choose according to the matching dimentions but if we want to choose we should use `tensordot`, but, again, we **do not need tensordot** for this class. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reese Witherspoon as a Rank 3 Tensor\n",
    "\n",
    "A common kind of data input to a neural network is images. Images are nice to look at, but remember, the computer only sees a series of numbers arranged in `tensors`. In this part we will look at how images are displayed and altered in Python. \n",
    "\n",
    "`matplotlib` supports only .png images but uses a library called `Pillow` to handle any image. If you do not have `Pillow` installed you can do this in anaconda:\n",
    "```\n",
    "conda install -c anaconda pillow \n",
    "\n",
    "OR \n",
    "\n",
    "pip install pillow\n",
    "```\n",
    "\n",
    "This image is from the dataset [Labeled Faces in the Wild](http://vis-www.cs.umass.edu/lfw/person/Reese_Witherspoon.html) used for machine learning training. Images are 24-bit RGB images (height, width, channels) with 8 bits for each of R, G, B channel. Explore and print the array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.image as mpimg\n",
    "\n",
    "# load and show the image\n",
    "FILE = '../fig/Reese_Witherspoon.jpg'\n",
    "img = mpimg.imread(FILE);\n",
    "imgplot = plt.imshow(img);\n",
    "\n",
    "print(f'The image is a: {type(img)} of shape {img.shape}')\n",
    "img[3:5, 3:5, :]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Slicing tensors: slice along each axis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we want to show each color channel\n",
    "fig, axes = plt.subplots(1, 3, figsize=(10,10))\n",
    "for i, subplot in zip(range(3), axes):\n",
    "    temp = np.zeros(img.shape, dtype='uint8')\n",
    "    temp[:,:,i] = img[:,:,i]\n",
    "    subplot.imshow(temp)\n",
    "    subplot.set_axis_off()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Multiplying Images with a scalar\n",
    "\n",
    "Just for fun, no real use for this lab!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = img\n",
    "temp = temp * 2\n",
    "plt.imshow(temp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For more on image manipulation by `matplotlib` see: [matplotlib-images](https://matplotlib.org/3.1.1/tutorials/introductory/images.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3: Building an Artificial Neural Network\n",
    "\n",
    "https://www.tensorflow.org/guide/keras\n",
    "\n",
    "`tf.keras` is TensorFlow's high-level API for building and training deep learning models. It's used for fast prototyping, state-of-the-art research, and production. `Keras` is a library created by François Chollet. After Google released Tensorflow 2.0, the creators of `keras` recommend that \"Keras users who use multi-backend Keras with the TensorFlow backend switch to `tf.keras` in TensorFlow 2.0. `tf.keras` is better maintained and has better integration with TensorFlow features\".\n",
    "\n",
    "NOTE:  In `Keras` everything starts with a Tensor of N samples as input and ends with a Tensor of N samples as output."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First you build it ...\n",
    "\n",
    "Parts of a NN:\n",
    "\n",
    "* Part 1: the input layer (our dataset)\n",
    "\n",
    "* Part 2: the internal architecture or hidden layers (the number of layers, the activation functions, the learnable parameters and other hyperparameters)\n",
    "* Part 3: the output layer (what we want from the network - classification or regression)\n",
    "\n",
    "### ... and then you train it!\n",
    "\n",
    "1. Load and pre-process the data\n",
    "2. Define the layers of the model.\n",
    "3. Compile the model.\n",
    "4. Fit the model to the train set (also using a validation set).\n",
    "5. Evaluate the model on the test set.\n",
    "6. We learn a lot by studying History! Plot metrics such as accuracy.\n",
    "7. Now let's use the Network for what it was meant to do: Predict on the test set!\n",
    "8. Try our model on a sandal from the Kanye West collection!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the seed for reproducability of results\n",
    "seed = 7\n",
    "np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fashion MNIST \n",
    "\n",
    "**Fashion-MNIST** is a dataset of clothing article images (created by [Zalando](https://github.com/zalandoresearch/fashion-mnist)), consisting of a training set of 60,000 examples and a test set of 10,000 examples. Each example is a **28 x 28** grayscale image, associated with a label from **10 classes**. The creators intend Fashion-MNIST to serve as a direct drop-in replacement for the original MNIST dataset for benchmarking machine learning algorithms. It shares the same image size and structure of training and testing splits. Each pixel is 8 bits so its value ranges from 0 to 255.\n",
    "\n",
    "Let's load and look at it!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Load and pre-process the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the data from keras - how convenient!\n",
    "fashion_mnist = tf.keras.datasets.fashion_mnist\n",
    "\n",
    "# load the data splitted in train and test! how nice!\n",
    "(x_train, y_train),(x_test, y_test) = fashion_mnist.load_data()\n",
    "\n",
    "# normalize the data by dividing with pixel intensity\n",
    "# (each pixel is 8 bits so its value ranges from 0 to 255)\n",
    "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
    "\n",
    "# classes are named 0-9 so define names for plotting clarity\n",
    "class_names = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat',\n",
    "               'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']\n",
    "\n",
    "plt.figure(figsize=(10,10))\n",
    "for i in range(25):\n",
    "    plt.subplot(5,5,i+1)\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    plt.grid(False)\n",
    "    plt.imshow(x_train[i], cmap=plt.cm.binary)\n",
    "    plt.xlabel(class_names[y_train[i]])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# choose one image to look at\n",
    "plt.imshow(x_train[3], cmap=plt.cm.binary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# take a look at the array shapes\n",
    "x_train.shape, x_test.shape, y_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Define the layers of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# type your code here along with instructor\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Compile the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# type your code here along with instructor\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print a summary of your model\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use this cool `tf.keras` method to visualize the layers of your network\n",
    "tf.keras.utils.plot_model(\n",
    "    model,\n",
    "    #to_file='model.png', # if you want to save the image\n",
    "    show_shapes=True, # True for more details than you need\n",
    "    show_layer_names=True,\n",
    "    rankdir='TB',\n",
    "    expand_nested=False,\n",
    "    dpi=96\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Everything you wanted to know about a Keras Model and were afraid to ask](https://www.tensorflow.org/api_docs/python/tf/keras/Model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. Fit the model to the train set (also using a validation set)\n",
    "\n",
    "This is the part that takes the longest in terms of time and where having GPUs helps.\n",
    "\n",
    "-----------------------------------------------------------\n",
    "**ep·och** <BR>\n",
    "noun: epoch; plural noun: epochs. A period of time in history or a person's life, typically one marked by notable events or particular characteristics. Examples: \"the Victorian epoch\", \"my Neural Netwok's epochs\". <BR>\n",
    "    \n",
    "-----------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# type your code here along with instructor\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Save the model\n",
    "\n",
    "You can save the model so you do not have `.fit` everytime you reset the kernel in the notebook. Network training is expensive!\n",
    "\n",
    "For more details on this see [https://www.tensorflow.org/guide/keras/save_and_serialize](https://www.tensorflow.org/guide/keras/save_and_serialize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the model so you do not have to run the code everytime\n",
    "model.save('fashion_model.h5')\n",
    "\n",
    "# Recreate the exact same model purely from the file\n",
    "#model = tf.keras.models.load_model('fashion_model.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5. Evaluate the model on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# type your code here along with instructor\n",
    "\n",
    "\n",
    "\n",
    "# print results\n",
    "print(f'Test accuracy={test_accuracy:.4f}')\n",
    "if test_accuracy>0.8: print(f'Not bad!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6. We learn a lot by studying History! Plot metrics such as accuracy. \n",
    "\n",
    "You can learn a lot about neural networks by observing how they perform while training. You can issue `kallbacks` in `keras`. The networks's performance is stored in a `keras` callback aptly named `history` which can be plotted. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(history.history.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot accuracy and loss for the test set\n",
    "fig, ax = plt.subplots(1,2, figsize=(20,6))\n",
    "\n",
    "ax[0].plot(history.history['accuracy'])\n",
    "ax[0].plot(history.history['val_accuracy'])\n",
    "ax[0].set_title('Model accuracy')\n",
    "ax[0].set_ylabel('accuracy')\n",
    "ax[0].set_xlabel('epoch')\n",
    "ax[0].legend(['train', 'val'], loc='best')\n",
    "\n",
    "ax[1].plot(history.history['loss'])\n",
    "ax[1].plot(history.history['val_loss'])\n",
    "ax[1].set_title('Model loss')\n",
    "ax[1].set_ylabel('loss')\n",
    "ax[1].set_xlabel('epoch')\n",
    "ax[1].legend(['train', 'val'], loc='best')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 7. Now let's use the Network for what it was meant to do: Predict on the test set!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# type your code here along with instructor\n",
    "\n",
    "\n",
    "\n",
    "# print results\n",
    "print(f'These are the Network\\'s predicted probabilities for each class for the first test image: \\n{predictions[0]}')\n",
    "print(f'Our Oracle says this is a class {np.argmax(predictions[0]):.2f}, which is a {class_names[np.argmax(predictions[0])]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see if our network predicted right! Does this item really look like what was predicted?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.imshow(x_test[0], cmap=plt.cm.binary)\n",
    "plt.xlabel(class_names[y_test[0]])\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's see how confident our model is by plotting the probability values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# code source: https://www.tensorflow.org/tutorials/keras/classification\n",
    "def plot_image(i, predictions_array, true_label, img):\n",
    "    predictions_array, true_label, img = predictions_array, true_label[i], img[i]\n",
    "    plt.grid(False)\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "\n",
    "    plt.imshow(img, cmap=plt.cm.binary)\n",
    "\n",
    "    predicted_label = np.argmax(predictions_array)\n",
    "    if predicted_label == true_label:\n",
    "        color = 'blue'\n",
    "    else:\n",
    "        color = 'red'\n",
    "\n",
    "    plt.xlabel(\"{} {:2.0f}% ({})\".format(class_names[predicted_label],\n",
    "                                100*np.max(predictions_array),\n",
    "                                class_names[true_label]),\n",
    "                                color=color)\n",
    "\n",
    "def plot_value_array(i, predictions_array, true_label):\n",
    "    predictions_array, true_label = predictions_array, true_label[i]\n",
    "    plt.grid(False)\n",
    "    plt.xticks(range(10))\n",
    "    plt.yticks([])\n",
    "    thisplot = plt.bar(range(10), predictions_array, color=\"#777777\")\n",
    "    plt.ylim([0, 1])\n",
    "    predicted_label = np.argmax(predictions_array)\n",
    "\n",
    "    thisplot[predicted_label].set_color('red')\n",
    "    thisplot[true_label].set_color('blue')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "plt.figure(figsize=(6,3))\n",
    "plt.subplot(1,2,1)\n",
    "plot_image(i, predictions[i], y_test, x_test)\n",
    "plt.subplot(1,2,2)\n",
    "plot_value_array(i, predictions[i],  y_test)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 8. Try our model on a sandal from the Kanye West collection!\n",
    "Let's see if our network can generalize beyond the MNIST fashion dataset. Let's give it a trendy shoe and see what it predicts. Here is the image:\n",
    "\n",
    "<img src=\"../fig/kanye_shoe.jpg\" alt=\"shoe\" width=\"150\" height=\"150\"><BR>\n",
    "<div class=\"exercise\"><b>In class discussion : What kinds of images can our model predict?</b></div>\n",
    "\n",
    "**Buzzword**: Generalization\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let'see the tensor shape\n",
    "shoe = np.array(Image.open('../fig/kanye_28.jpg'))\n",
    "shoe.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We need to delete the other 2 channels and make the image B&W. \n",
    "shoe = shoe[:,:,0]\n",
    "shoe.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.imshow(shoe, cmap=plt.cm.binary)\n",
    "plt.xlabel('a cool shoe')\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`tf.keras` models are optimized to make predictions on a batch, or collection, of examples at once. Accordingly, even though you're using a single image, you need to add it to a list:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the image to a batch where it's the only member.\n",
    "shoe_batch = (np.expand_dims(shoe,0))\n",
    "print(shoe_batch.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write the code to predict here\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"exercise\"><b>In class discussion : How did our model perform?</b></div>\n",
    "    \n",
    "**Buzzword:** Convolutional Neural Networks!\n",
    "\n",
    "Let's now try a different boot:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "boot = np.array(Image.open('../fig/random_boot.png'))\n",
    "plt.figure()\n",
    "plt.imshow(boot, cmap=plt.cm.binary)\n",
    "plt.xlabel('random boot from web')\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make into one channel\n",
    "boot = boot[:,:,0]\n",
    "boot.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "boots = (np.expand_dims(boot,0))\n",
    "print(boot.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_single = model.predict(boots)\n",
    "print(predictions_single[0])\n",
    "print(np.argmax(predictions_single[0]), class_names[np.argmax(predictions_single[0])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if it's either a sneaker or a boot we are good\n",
    "if np.argmax(predictions_single[0]) in [7,9]: print(f'We did better this time!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regularization\n",
    "Let's try adding a regularizer in our model. For more see `tf.keras` [regularizers](https://www.tensorflow.org/api_docs/python/tf/keras/regularizers).<BR>\n",
    "\n",
    "1. Norm penalties: `kernel_regularizer= tf.keras.regularizers.l2(l=0.1)`\n",
    "2. Early stopping via `tf.keras.callbacks`. Callbacks provide a way to interact with the model while it's training and inforce some decisions automatically. Callbacks need to be instantiated and are added to the `.fit()` function via the `callbacks` argument.\n",
    "3. Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# callbacks\n",
    "# watch validation loss and be \"patient\" for 50 epochs of no improvement\n",
    "#es = tf.keras.callbacks.EarlyStopping(monitor='val_loss', verbose=1, patience=30)\n",
    "\n",
    "model_regular = tf.keras.models.Sequential([\n",
    "  tf.keras.layers.Flatten(input_shape=(28, 28)),\n",
    "  tf.keras.layers.Dense(154, activation='relu', \n",
    "                        kernel_regularizer= tf.keras.regularizers.l2(l=0.1)),\n",
    "  tf.keras.layers.Dropout(0.2),\n",
    "  tf.keras.layers.Dense(64, activation='relu', \n",
    "                       kernel_regularizer= tf.keras.regularizers.l2(l=0.1)),\n",
    "  tf.keras.layers.Dense(10, activation='softmax')\n",
    "])\n",
    "\n",
    "# compile\n",
    "loss_fn = tf.keras.losses.SparseCategoricalCrossentropy()\n",
    "optimizer = tf.keras.optimizers.Adam()\n",
    "\n",
    "model_regular.compile(optimizer=optimizer,\n",
    "              loss=loss_fn,\n",
    "              metrics=['accuracy'])\n",
    "# fit\n",
    "history_regular = model_regular.fit(x_train, y_train, validation_split=0.33, epochs=50, \n",
    "                    verbose=2) #, callbacks=[es])\n",
    "                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loss, test_accuracy = model_regular.evaluate(x_test, y_test, verbose=0)\n",
    "print(f'Test accuracy for regularized model={test_accuracy}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot accuracy and loss for the test set\n",
    "fig, ax = plt.subplots(1,2, figsize=(20,6))\n",
    "\n",
    "ax[0].plot(history_regular.history['accuracy'])\n",
    "ax[0].plot(history_regular.history['val_accuracy'])\n",
    "ax[0].set_title('Regularized Model accuracy')\n",
    "ax[0].set_ylabel('accuracy')\n",
    "ax[0].set_xlabel('epoch')\n",
    "ax[0].legend(['train', 'val'], loc='best')\n",
    "\n",
    "ax[1].plot(history_regular.history['loss'])\n",
    "ax[1].plot(history_regular.history['val_loss'])\n",
    "ax[1].set_title('Regularized Model loss')\n",
    "ax[1].set_ylabel('loss')\n",
    "ax[1].set_xlabel('epoch')\n",
    "ax[1].legend(['train', 'val'], loc='best')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
