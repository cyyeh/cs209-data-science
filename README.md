# CS209 Data Science

This repo contains a series of data science courses from Harvard. What's special about these three courses is that the course content is the most complete one I've ever seen. The first course(a.k.a `a`) and the second course(a.k.a `b`) together is the introduction to data science. If you have heard about [CS109](https://github.com/cyyeh/cs109-data-science) from Harvard before, the material is a lot similar with `a`; and `b` contains more recent and advanced techniques in deep learning. The last course from the series(a.k.a `c`) mainly talks about three things: 1. how to scale a model from a prototype(often in jupyter notebooks) to the cloud; 2. transfer learning; 3. visualization tools for investigating deep learning models.

## Courses Overview

### `a`

The course focuses on the analysis of messy, real life data to perform predictions using statistical and machine learning methods.

The material will integrate the five key facets of an investigation using data:

1. data collection ‐ data wrangling, cleaning, and sampling to get a suitable data set;

2. data management ‐ accessing data quickly and reliably;

3. exploratory data analysis – generating hypotheses and building intuition;

4. prediction or statistical learning; and

5. communication – summarizing results through visualization, stories, and interpretable summaries.

### `b`

The course introduces advanced methods for data wrangling, data visualization, and deep neural networks, statistical modeling, and prediction. Topics include big data and database management,  multiple deep learning subjects such as CNNs, RNNs, autoencoders, and generative models as well as basic Bayesian methods, nonlinear statistical models and unsupervised learning.

### `c`

The course will be divided into three major topics:

1. How to scale a model from a prototype (often in jupyter notebooks) to the cloud. In this module, we cover virtual environments, containers, and virtual machines before learning about microservices and Kubernetes. Along the way, students will be exposed to Dask.

2. How to use existing models for transfer learning. Transfer learning is a machine learning method where a model developed for a task is reused as the starting point for a model on a second task. It is a popular approach in deep learning where pre-trained models are used as the starting point on computer vision and natural language processing tasks. This can be very important, given the vast compute and time resources required to develop neural network models on these problems and given the huge jumps in skill that these models can provide to related problems. In this part of the course we will examine various pre-existing models and techniques in transfer learning.

3. In the third part we will be introducing a number of intuitive visualization tools for investigating properties and diagnosing issues of models. We will be demonstrating a number of visualization tools ranging from the well established (like saliency maps) to recent ones that have appeared in https://distill.pub.

## References

- [course website of `a`](https://harvard-iacs.github.io/2019-CS109A/)
- [course website of `b`](https://harvard-iacs.github.io/2019-CS109B/)
- [course website of `c`](https://harvard-iacs.github.io/2020-AC295/)